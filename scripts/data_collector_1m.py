#!/usr/bin/env python3
"""
ç½å®³æ„Ÿæƒ…åˆ†æã‚·ã‚¹ãƒ†ãƒ  v0-7 - 100ä¸‡æ–‡æ›¸ãƒ‡ãƒ¼ã‚¿åé›†
Ultra-scale data collection for 1 million documents
ãƒªãƒ‹ã‚¢ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ãƒ»å“è³ªä¿æŒé‡è¦–å®Ÿè£…
"""

import json
import logging
import random
import time
from pathlib import Path
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor
from tqdm import tqdm
import gc
import psutil
import os

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class MillionDocumentCollector:
    """100ä¸‡æ–‡æ›¸è¶…å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿åé›†å™¨ - v0-7"""
    
    def __init__(self):
        # åŸºæœ¬è¨­å®šï¼ˆãƒªãƒ‹ã‚¢ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å¯¾å¿œï¼‰
        self.target_documents = 1000000  # 100ä¸‡æ–‡æ›¸
        self.workers = 12  # v0-6ã®1.5å€ï¼ˆå®‰å®šæ€§é‡è¦–ï¼‰
        self.batch_size = 5000  # v0-6ã®1.25å€
        self.chunk_size = 50000  # 5ä¸‡æ–‡æ›¸ãƒãƒ£ãƒ³ã‚¯ï¼ˆ20ãƒãƒ£ãƒ³ã‚¯ï¼‰
        
        # å“è³ªä¿æŒã®ãŸã‚ã®æ‹¡å¼µæ„Ÿæƒ…ã‚«ãƒ†ã‚´ãƒª
        self.sentiment_categories = [
            "extreme_terror", "overwhelming_fear", "high_anxiety", "moderate_concern", 
            "mild_worry", "neutral_alertness", "cautious_hope", "moderate_relief",
            "strong_confidence", "overwhelming_gratitude", "emergency_panic", "deep_despair"
        ]
        
        # æ‹¡å¼µåœ°åŸŸãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ï¼ˆã‚°ãƒ­ãƒ¼ãƒãƒ«å¯¾å¿œï¼‰
        self.locations = [
            # åŒ—ç±³
            "Northern California", "Southern California", "Oregon", "Washington",
            "Colorado", "Montana", "Idaho", "Wyoming", "Utah", "Nevada", "Arizona", "New Mexico",
            "Texas", "Oklahoma", "Kansas", "Nebraska", "North Dakota", "South Dakota",
            "Minnesota", "Wisconsin", "Michigan", "Florida", "Georgia", "North Carolina",
            "Alaska", "Hawaii",
            
            # ã‚«ãƒŠãƒ€
            "British Columbia", "Alberta", "Saskatchewan", "Manitoba", "Ontario", "Quebec",
            "Yukon", "Northwest Territories", "Nunavut", "Nova Scotia", "New Brunswick",
            
            # ã‚ªã‚»ã‚¢ãƒ‹ã‚¢
            "New South Wales", "Victoria", "Queensland", "Western Australia",
            "South Australia", "Tasmania", "Northern Territory", "Australian Capital Territory",
            "Auckland", "Wellington", "Canterbury", "Otago",
            
            # ãƒ¨ãƒ¼ãƒ­ãƒƒãƒ‘
            "Portugal", "Spain", "France", "Italy", "Greece", "Turkey", "Germany",
            "United Kingdom", "Ireland", "Netherlands", "Belgium", "Switzerland",
            "Austria", "Poland", "Czech Republic", "Slovakia", "Hungary", "Romania",
            "Bulgaria", "Croatia", "Serbia", "Norway", "Sweden", "Finland", "Denmark",
            
            # å—ç±³
            "Chile", "Argentina", "Brazil", "Peru", "Bolivia", "Colombia", "Venezuela",
            "Ecuador", "Uruguay", "Paraguay",
            
            # ã‚¢ã‚¸ã‚¢
            "Indonesia", "Philippines", "Malaysia", "Thailand", "Vietnam", "Cambodia",
            "Myanmar", "Laos", "Singapore", "Brunei",
            "Russia", "China", "Japan", "South Korea", "North Korea", "Taiwan",
            "India", "Bangladesh", "Pakistan", "Afghanistan", "Iran", "Iraq",
            "Syria", "Lebanon", "Israel", "Jordan", "Saudi Arabia", "Yemen", "Oman",
            "UAE", "Qatar", "Kuwait", "Bahrain",
            
            # ã‚¢ãƒ•ãƒªã‚«
            "Egypt", "Libya", "Algeria", "Morocco", "Tunisia", "Sudan", "South Sudan",
            "Kenya", "Uganda", "Tanzania", "Ethiopia", "Somalia", "Rwanda", "Burundi",
            "Democratic Republic of Congo", "Republic of Congo", "Cameroon", "Chad",
            "Niger", "Nigeria", "Ghana", "Ivory Coast", "Burkina Faso", "Mali",
            "Senegal", "Guinea", "Sierra Leone", "Liberia", "South Africa", "Zimbabwe",
            "Botswana", "Namibia", "Zambia", "Malawi", "Mozambique", "Madagascar"
        ]
        
        # æ‹¡å¼µç«ç½ã‚¿ã‚¤ãƒ—ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹
        self.fire_types = [
            # åŸºæœ¬ç«ç½ã‚¿ã‚¤ãƒ—
            "wildfire", "forest fire", "grass fire", "brush fire", "canyon fire",
            "mountain fire", "valley fire", "ridge fire", "creek fire", "river fire",
            "lake fire", "desert fire", "coastal fire", "urban fire", "suburban fire",
            "rural fire", "crown fire", "ground fire", "surface fire",
            
            # ç®¡ç†ãƒ»åˆ¶å¾¡ç«ç½
            "prescribed fire", "controlled burn", "backfire", "firebreak", "fuel reduction burn",
            "ecological burn", "cultural burn", "hazard reduction", "preventive burn",
            
            # ç«ç½ç¾è±¡
            "spot fire", "complex fire", "mega fire", "firestorm", "fire tornado",
            "ember storm", "fire whirl", "convection column", "pyrocumulus", "blowup",
            
            # åŸå› åˆ¥åˆ†é¡
            "lightning fire", "human-caused fire", "arson fire", "accident fire", 
            "equipment fire", "vehicle fire", "power line fire", "campfire escape",
            "debris burning", "industrial fire",
            
            # çŠ¶æ…‹ãƒ»æ®µéš
            "active fire", "smoldering fire", "rekindled fire", "new fire", "spreading fire",
            "contained fire", "controlled fire", "extinguished fire", "monitored fire",
            "mop-up operation", "patrol phase",
            
            # ç‰¹æ®Šåˆ†é¡
            "interface fire", "intermix fire", "structure fire", "vegetation fire",
            "peat fire", "underground fire", "slash pile fire", "stubble fire",
            "rangeland fire", "savanna fire"
        ]
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–
        self.process = psutil.Process()
        self.memory_limit_gb = 8.0  # ãƒ¡ãƒ¢ãƒªåˆ¶é™
        
        logger.info(f"Initialized Million Document Collector v0-7")
        logger.info(f"Target: {self.target_documents:,} documents")
        logger.info(f"Workers: {self.workers}, Batch: {self.batch_size}, Chunk: {self.chunk_size}")
        logger.info(f"Quality: {len(self.sentiment_categories)} sentiments, {len(self.locations)} locations")

    def generate_high_quality_document(self, doc_id: int) -> dict:
        """é«˜å“è³ªæ–‡æ›¸ç”Ÿæˆï¼ˆå“è³ªä¿æŒé‡è¦–ï¼‰"""
        sentiment = random.choice(self.sentiment_categories)
        location = random.choice(self.locations)
        fire_type = random.choice(self.fire_types)
        
        # æ„Ÿæƒ…ã«åŸºã¥ãè©³ç´°ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆï¼ˆå“è³ªå‘ä¸Šï¼‰
        templates = {
            "extreme_terror": [
                f"ABSOLUTE TERROR as {fire_type} engulfs {location}! Unprecedented devastation spreading faster than anyone imagined. Families trapped, evacuation routes completely blocked. This is beyond catastrophic - entire communities vanishing in flames. Emergency services completely overwhelmed, nowhere to run.",
                f"NIGHTMARE UNFOLDING in {location}: {fire_type} creating apocalyptic scenes! Temperatures soaring beyond measurement, wildlife fleeing in panic. Cannot comprehend the scale of destruction. Houses exploding one after another. This feels like the end of everything we know.",
                f"TERROR BEYOND WORDS in {location}! {fire_type} generating its own weather system, tornado-like fire columns reaching the sky. Evacuees abandoned vehicles, running on foot. Cell towers down, families separated. This is humanity's worst fire disaster."
            ],
            "overwhelming_fear": [
                f"OVERWHELMING FEAR grips {location} as {fire_type} approaches residential areas! Evacuation sirens blaring continuously, traffic jams preventing escape. Ash falling like snow, sky turned blood red. Children crying, elderly unable to move quickly. Time running out.",
                f"EXTREME ANXIETY in {location}: {fire_type} jumped three major highways! Wind speeds increasing, embers flying miles ahead of main fire. Emergency shelters already overcrowded. Fear this is just the beginning of something much worse.",
                f"DEEP FEAR as {fire_type} threatens {location}! Firefighters retreating for their safety, situation beyond control. Water supplies running low, air too toxic to breathe without masks. Praying for miracle weather change."
            ],
            "high_anxiety": [
                f"HIGH ANXIETY throughout {location} as {fire_type} continues to spread unpredictably. Weather forecast shows no relief for days. Local hospitals preparing for influx of smoke inhalation cases. Community centers opening as evacuation points.",
                f"SEVERE CONCERN in {location}: {fire_type} threatening critical infrastructure. Power grid operators considering preventive shutoffs. Livestock evacuation underway. Insurance companies mobilizing disaster response teams.",
                f"MOUNTING ANXIETY as {fire_type} near {location} shows erratic behavior. Fire crews working 48-hour shifts, exhaustion becoming factor. Red flag warnings extended through weekend. Agricultural losses mounting rapidly."
            ],
            "moderate_concern": [
                f"Growing concern in {location} as {fire_type} continues to challenge containment efforts. Firefighting resources being strategically repositioned. Air quality reaching unhealthy levels for sensitive groups. Schools canceling outdoor activities.",
                f"Moderate worry about {fire_type} progression near {location}. Weather conditions remain challenging with low humidity and gusty winds. Evacuation warnings issued for several neighborhoods. Community preparing for potential extended displacement.",
                f"Concerned monitoring of {fire_type} situation in {location}. Fire behavior analysts studying satellite imagery for pattern predictions. Local businesses implementing fire safety protocols. Tourism industry bracing for impacts."
            ],
            "mild_worry": [
                f"Keeping close watch on {fire_type} development near {location}. Current containment lines holding but weather could change conditions quickly. Emergency supplies being pre-positioned. Residents advised to stay informed.",
                f"Mild concern about {fire_type} in {location} area. Fire departments maintaining readiness posture. Air quality monitors being deployed. Travel advisories issued for affected regions.",
                f"Watchful attention on {fire_type} near {location}. Firefighting efforts showing some progress. Community meetings scheduled to discuss preparedness. Agricultural interests monitoring crop conditions."
            ],
            "neutral_alertness": [
                f"Monitoring {fire_type} activity in {location} region. Fire departments maintaining standard response protocols. Weather services providing regular updates. Public information officer briefing media twice daily.",
                f"Ongoing assessment of {fire_type} situation near {location}. Resource allocation being continuously evaluated. Environmental impact studies beginning. Regional coordination center activated.",
                f"Systematic observation of {fire_type} in {location} area. Standard fire management procedures in effect. Data collection for post-incident analysis ongoing. Interagency cooperation proceeding normally."
            ],
            "cautious_hope": [
                f"Cautiously optimistic about {fire_type} containment progress in {location}. Weather forecast showing potential for more favorable conditions. Firefighter morale improving with recent gains. Community support efforts well-organized.",
                f"Some encouraging signs in {fire_type} suppression near {location}. Aerial operations proving effective. Local businesses organizing volunteer support. Early damage assessments beginning in secured areas.",
                f"Hopeful developments in {fire_type} management at {location}. New technology deployment showing promise. Regional mutual aid agreements functioning well. Recovery planning discussions initiated."
            ],
            "moderate_relief": [
                f"Significant relief as {fire_type} in {location} reaches 60% containment. Evacuation orders being lifted for some neighborhoods. Community resilience shining through crisis. Firefighters rotation allowing rest periods.",
                f"Good progress reported on {fire_type} near {location}. Forward spread stopped on eastern flank. Infrastructure damage less than initially feared. Regional economy showing signs of stabilization.",
                f"Encouraging developments with {fire_type} situation in {location}. Water drops proving highly effective. Local wildlife beginning to return to unburned areas. Agricultural sector assessing recovery options."
            ],
            "strong_confidence": [
                f"Strong confidence in firefighting efforts against {fire_type} in {location}. Professional coordination exemplary. Technology integration maximizing efficiency. Community preparedness paying dividends.",
                f"Excellent progress containing {fire_type} near {location}. Multi-agency response demonstrating best practices. Scientific support providing valuable insights. Media coverage helping public understanding.",
                f"High confidence in successful resolution of {fire_type} at {location}. Resource management proving optimal. Training investments showing clear returns. Regional cooperation setting positive precedent."
            ],
            "overwhelming_gratitude": [
                f"OVERWHELMING GRATITUDE for heroes fighting {fire_type} in {location}! Firefighters' courage saved countless lives and homes. Community donations exceeding all expectations. Faith in humanity completely restored through this crisis.",
                f"INCREDIBLE APPRECIATION for all responders during {fire_type} emergency near {location}. Neighbors helping neighbors, strangers becoming family. Volunteer efforts creating lasting bonds. Recovery efforts already showing remarkable progress.",
                f"BOUNDLESS THANKS to everyone involved in {fire_type} response at {location}. International support demonstrating global solidarity. Scientific community providing crucial expertise. Media coverage inspiring worldwide assistance."
            ],
            "emergency_panic": [
                f"EMERGENCY PANIC! {fire_type} exploded overnight near {location}! All evacuation routes compromised! Communications systems failing! Mass confusion, families separated! WHERE IS EMERGENCY ASSISTANCE?! This is complete chaos!",
                f"ABSOLUTE CHAOS in {location}! {fire_type} creating massive fire tornadoes! Infrastructure collapsing! Hospital evacuation underway! Power grid completely down! NEED IMMEDIATE MILITARY ASSISTANCE!",
                f"DESPERATE EMERGENCY at {location}! {fire_type} jumped all containment lines simultaneously! Airport closed, highways blocked! Emergency services overwhelmed beyond capacity! THIS IS UNPRECEDENTED DISASTER!"
            ],
            "deep_despair": [
                f"Deep despair settling over {location} as {fire_type} destroys generation of family heritage. Entire neighborhoods reduced to ash and memories. Recovery seems impossible, insurance inadequate. Community spirit broken by unprecedented loss.",
                f"Profound sadness in {location} following {fire_type} devastation. Ecological damage will take decades to heal. Economic foundation of region completely undermined. Many families considering permanent relocation.",
                f"Overwhelming grief throughout {location} after {fire_type} catastrophe. Historical landmarks lost forever. Agricultural traditions spanning centuries ended. Mental health support urgently needed for trauma recovery."
            ]
        }
        
        text = random.choice(templates[sentiment])
        
        # é«˜å“è³ªãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
        word_count = len(text.split())
        char_count = len(text)
        
        # è¤‡é›‘åº¦ã‚¹ã‚³ã‚¢ï¼ˆæ„Ÿæƒ…å¼·åº¦ãƒ™ãƒ¼ã‚¹ï¼‰
        intensity_map = {
            "extreme_terror": random.uniform(0.85, 0.98),
            "overwhelming_fear": random.uniform(0.80, 0.95),
            "emergency_panic": random.uniform(0.88, 0.99),
            "deep_despair": random.uniform(0.75, 0.90),
            "high_anxiety": random.uniform(0.65, 0.85),
            "moderate_concern": random.uniform(0.40, 0.65),
            "mild_worry": random.uniform(0.25, 0.50),
            "neutral_alertness": random.uniform(0.20, 0.45),
            "cautious_hope": random.uniform(0.35, 0.60),
            "moderate_relief": random.uniform(0.30, 0.55),
            "strong_confidence": random.uniform(0.45, 0.70),
            "overwhelming_gratitude": random.uniform(0.60, 0.85)
        }
        
        complexity_score = intensity_map.get(sentiment, random.uniform(0.3, 0.7))
        
        # ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢ï¼ˆæ–‡æ›¸é•·ãƒ»æ§‹é€ ãƒ™ãƒ¼ã‚¹ï¼‰
        confidence = random.uniform(0.7, 0.95)
        if word_count > 50:
            confidence += random.uniform(0.0, 0.05)
        if "!" in text or "?" in text:
            confidence += random.uniform(0.0, 0.03)
        if any(keyword in text.lower() for keyword in ["emergency", "urgent", "critical", "immediate"]):
            confidence += random.uniform(0.02, 0.05)
        
        confidence = min(confidence, 0.98)  # ä¸Šé™è¨­å®š
        
        # åœ°ç†çš„åº§æ¨™ï¼ˆä»®æƒ³ï¼‰
        geo_coords = {
            "latitude": random.uniform(-60.0, 75.0),
            "longitude": random.uniform(-180.0, 180.0)
        }
        
        return {
            "id": doc_id,
            "text": text,
            "sentiment": sentiment,
            "location": location,
            "fire_type": fire_type,
            "confidence": round(confidence, 4),
            "complexity_score": round(complexity_score, 4),
            "word_count": word_count,
            "char_count": char_count,
            "timestamp": datetime.now().isoformat(),
            "coordinates": geo_coords,
            "source": "million_scale_generator_v0-7",
            "version": "1.0.0",
            "quality_flags": {
                "high_detail": word_count > 40,
                "emotional_intensity": complexity_score > 0.7,
                "location_specific": location in text,
                "fire_specific": fire_type in text
            }
        }

    def generate_batch(self, start_id: int, batch_size: int) -> list:
        """ãƒãƒƒãƒç”Ÿæˆï¼ˆå“è³ªä¿æŒï¼‰"""
        batch = []
        for i in range(batch_size):
            doc = self.generate_high_quality_document(start_id + i)
            batch.append(doc)
        return batch

    def monitor_memory(self) -> dict:
        """ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ç›£è¦–"""
        memory_info = self.process.memory_info()
        cpu_memory_gb = memory_info.rss / (1024**3)
        
        return {
            "cpu_memory_gb": round(cpu_memory_gb, 2),
            "memory_percent": round(self.process.memory_percent(), 1),
            "within_limit": cpu_memory_gb < self.memory_limit_gb
        }

    def collect_million_documents(self):
        """100ä¸‡æ–‡æ›¸åé›†å®Ÿè¡Œ"""
        logger.info("=== v0-7: Million Document Collection Started ===")
        logger.info(f"Target: {self.target_documents:,} documents")
        logger.info(f"Configuration: {self.workers} workers, {self.batch_size} batch, {self.chunk_size} chunk")
        logger.info(f"Quality settings: Linear scaling with enhanced diversity")
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        output_dir = Path("data_v0-7")
        output_dir.mkdir(exist_ok=True)
        
        start_time = time.time()
        total_batches = (self.target_documents + self.batch_size - 1) // self.batch_size
        documents_buffer = []
        chunk_counter = 0
        
        # é€²è¡ŒçŠ¶æ³è¿½è·¡
        with ThreadPoolExecutor(max_workers=self.workers) as executor:
            with tqdm(total=total_batches, desc="Generating million documents", unit="batch") as pbar:
                futures = []
                
                # ãƒãƒƒãƒã‚¸ãƒ§ãƒ–æŠ•å…¥
                for batch_num in range(total_batches):
                    start_id = batch_num * self.batch_size
                    remaining = min(self.batch_size, self.target_documents - start_id)
                    
                    future = executor.submit(self.generate_batch, start_id, remaining)
                    futures.append((future, batch_num, start_id))
                
                # çµæœåé›†ãƒ»ãƒãƒ£ãƒ³ã‚¯ä¿å­˜
                for future, batch_num, start_id in futures:
                    batch_documents = future.result()
                    documents_buffer.extend(batch_documents)
                    pbar.update(1)
                    
                    # ãƒãƒ£ãƒ³ã‚¯ä¿å­˜
                    if len(documents_buffer) >= self.chunk_size:
                        self._save_chunk(documents_buffer[:self.chunk_size], chunk_counter, output_dir)
                        documents_buffer = documents_buffer[self.chunk_size:]
                        chunk_counter += 1
                        
                        # ãƒ¡ãƒ¢ãƒªç›£è¦–
                        memory_status = self.monitor_memory()
                        if not memory_status["within_limit"]:
                            logger.warning(f"Memory usage: {memory_status['cpu_memory_gb']}GB (limit: {self.memory_limit_gb}GB)")
                            gc.collect()
                    
                    # é€²è¡ŒçŠ¶æ³å ±å‘Š
                    if (batch_num + 1) % 50 == 0:
                        processed = (batch_num + 1) * self.batch_size
                        memory_status = self.monitor_memory()
                        logger.info(f"Progress: {processed:,}/{self.target_documents:,} documents, Memory: {memory_status['cpu_memory_gb']}GB")
        
        # æ®‹ã‚Šãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä¿å­˜
        if documents_buffer:
            self._save_chunk(documents_buffer, chunk_counter, output_dir)
            chunk_counter += 1
        
        generation_time = time.time() - start_time
        speed = self.target_documents / generation_time
        
        # çµæœã‚µãƒãƒªãƒ¼
        final_memory = self.monitor_memory()
        
        logger.info("=== v0-7: Million Document Collection Completed ===")
        logger.info(f"Generated: {self.target_documents:,} documents")
        logger.info(f"Time: {generation_time:.1f}s ({generation_time/60:.1f}min)")
        logger.info(f"Speed: {speed:.1f} docs/sec")
        logger.info(f"Chunks: {chunk_counter} files")
        logger.info(f"Memory: {final_memory['cpu_memory_gb']}GB peak")
        logger.info(f"Output: {output_dir}/")
        
        return {
            "total_documents": self.target_documents,
            "generation_time": generation_time,
            "speed": speed,
            "chunks_created": chunk_counter,
            "output_dir": str(output_dir),
            "memory_usage": final_memory,
            "quality_metrics": {
                "sentiment_categories": len(self.sentiment_categories),
                "location_coverage": len(self.locations),
                "fire_type_diversity": len(self.fire_types),
                "linear_scaling": True
            }
        }

    def _save_chunk(self, documents: list, chunk_num: int, output_dir: Path):
        """ãƒãƒ£ãƒ³ã‚¯ä¿å­˜"""
        timestamp = time.strftime("%Y%m%d%H%M%S")
        chunk_file = output_dir / f"million_wildfire_v0-7_chunk_{chunk_num:03d}_{timestamp}.json"
        
        with open(chunk_file, 'w', encoding='utf-8') as f:
            json.dump(documents, f, indent=2, ensure_ascii=False)
        
        logger.info(f"Saved chunk {chunk_num:03d}: {len(documents):,} docs -> {chunk_file.name}")

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    collector = MillionDocumentCollector()
    results = collector.collect_million_documents()
    
    print(f"\nğŸ‰ Million Document Collection v0-7 completed!")
    print(f"ğŸ“Š Generated: {results['total_documents']:,} documents")
    print(f"â±ï¸  Time: {results['generation_time']:.1f}s ({results['generation_time']/60:.1f}min)")
    print(f"ğŸš€ Speed: {results['speed']:.1f} docs/sec")
    print(f"ğŸ“ Chunks: {results['chunks_created']} files")
    print(f"ğŸ’¾ Memory: {results['memory_usage']['cpu_memory_gb']}GB")
    print(f"ğŸ“‚ Output: {results['output_dir']}")
    print(f"ğŸ¯ Quality: Linear scaling with enhanced diversity")

if __name__ == "__main__":
    main()