#!/usr/bin/env python3
"""
NASA FIRMS Real Data Collection Demo
MAP_KEYã‚’è¨­å®šã—ãŸå ´åˆã®å®Ÿãƒ‡ãƒ¼ã‚¿åé›†ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
"""

import json
import logging
import os
import sys
from pathlib import Path
from dotenv import load_dotenv

# .envãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã¿
load_dotenv(Path(__file__).parent.parent / '.env')

# Add parent directory to path for imports
sys.path.append(str(Path(__file__).parent))

from public_wildfire_collector import PublicWildfireDataCollector, PublicDataConfig

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def demo_template_based_collection():
    """ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ™ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿åé›†ãƒ‡ãƒ¢"""
    print("ğŸŒ² Template-Based Data Collection Demo")
    print("=" * 50)
    
    # å°è¦æ¨¡ãƒ†ã‚¹ãƒˆè¨­å®š
    config = PublicDataConfig()
    config.target_documents = 300  # 3ã‚½ãƒ¼ã‚¹ Ã— 100æ–‡æ›¸
    config.output_dir = "demo_output_template"
    
    collector = PublicWildfireDataCollector(config)
    
    try:
        # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿åé›†
        collected_data = collector.collect_all_public_data()
        
        # çµæœã‚µãƒãƒªãƒ¼
        source_counts = {}
        for item in collected_data:
            source = item.get('source', 'Unknown')
            source_counts[source] = source_counts.get(source, 0) + 1
        
        print(f"\nâœ… Collection Results:")
        print(f"   Total: {len(collected_data)} documents")
        print(f"   Sources:")
        for source, count in source_counts.items():
            print(f"     - {source}: {count} documents")
        
        # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿è¡¨ç¤º
        print(f"\nğŸ“ Sample Data:")
        for i, item in enumerate(collected_data[:3]):
            print(f"   {i+1}. Source: {item.get('source', 'N/A')}")
            print(f"      Text: {item.get('text', 'N/A')[:100]}...")
            print(f"      Location: {item.get('location', 'N/A')}")
            print()
        
        return collected_data
        
    except Exception as e:
        logger.error(f"Template collection failed: {e}")
        return []

def demo_real_data_collection_simulation():
    """å®Ÿãƒ‡ãƒ¼ã‚¿åé›†ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆMAP_KEYæœªè¨­å®šã®å ´åˆï¼‰"""
    print("ğŸ›°ï¸  Real Data Collection Simulation")
    print("=" * 50)
    
    # MAP_KEYè¨­å®šãƒã‚§ãƒƒã‚¯
    map_key = os.getenv('NASA_FIRMS_MAP_KEY')
    
    if not map_key:
        print("âš ï¸  NASA_FIRMS_MAP_KEY not configured")
        print("   This would normally collect real VIIRS satellite fire data")
        print("   Steps to enable real data collection:")
        print("   1. Visit: https://firms.modaps.eosdis.nasa.gov/api/map_key/")
        print("   2. Enter your email to receive free MAP_KEY")
        print("   3. Set environment variable: NASA_FIRMS_MAP_KEY=your_key")
        print("   4. Re-run this demo")
        print()
        
        # ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ä¾‹
        print("ğŸ“Š Simulated Real Data Collection:")
        print("   - Query: North America (7 days)")
        print("   - Sources: VIIRS_SNPP_NRT, VIIRS_NOAA20_NRT, VIIRS_NOAA21_NRT")
        print("   - Expected: 50-500 real fire detections")
        print("   - Data format: CSV with lat/lon, brightness, confidence, FRP")
        print("   - Text generation: Japanese fire reports from satellite data")
        
        return []
    else:
        print(f"âœ… MAP_KEY configured: {map_key[:8]}...")
        
        # å®Ÿãƒ‡ãƒ¼ã‚¿åé›†ãƒ†ã‚¹ãƒˆ
        config = PublicDataConfig()
        config.nasa_firms_map_key = map_key
        config.firms_default_days = 3  # çŸ­æœŸé–“ã§ãƒ†ã‚¹ãƒˆ
        
        collector = PublicWildfireDataCollector(config)
        
        try:
            # NASA FIRMSãƒ‡ãƒ¼ã‚¿ã®ã¿åé›†
            real_data = collector.collect_nasa_firms_real_data()
            
            print(f"âœ… Real data collection results:")
            print(f"   Total fire detections: {len(real_data)}")
            
            if real_data:
                # ã‚µãƒ³ãƒ—ãƒ«è¡¨ç¤º
                print(f"\nğŸ“ Real Fire Detection Sample:")
                for i, fire in enumerate(real_data[:2]):
                    print(f"   {i+1}. {fire.get('text', 'N/A')[:150]}...")
                    coords = fire.get('coordinates', {})
                    print(f"      Coordinates: {coords.get('latitude', 'N/A')}, {coords.get('longitude', 'N/A')}")
                    print(f"      Intensity: {fire.get('fire_intensity', 'N/A')}")
                    print()
            
            return real_data
            
        except Exception as e:
            logger.error(f"Real data collection failed: {e}")
            return []

def demo_combined_pipeline():
    """çµ±åˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãƒ‡ãƒ¢"""
    print("ğŸ”— Combined Pipeline Demo")
    print("=" * 50)
    
    # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ + å®Ÿãƒ‡ãƒ¼ã‚¿çµ±åˆè¨­å®š
    config = PublicDataConfig()
    config.target_documents = 150  # å°è¦æ¨¡ãƒ†ã‚¹ãƒˆ
    config.output_dir = "demo_output_combined"
    
    # MAP_KEYè¨­å®šãŒã‚ã‚Œã°å®Ÿãƒ‡ãƒ¼ã‚¿ã‚‚å«ã‚ã‚‹
    map_key = os.getenv('NASA_FIRMS_MAP_KEY')
    if map_key:
        config.nasa_firms_map_key = map_key
    
    collector = PublicWildfireDataCollector(config)
    
    try:
        # çµ±åˆãƒ‡ãƒ¼ã‚¿åé›†
        combined_data = collector.collect_all_public_data()
        
        # ã‚½ãƒ¼ã‚¹åˆ¥åˆ†æ
        source_analysis = {}
        for item in combined_data:
            source = item.get('source', 'Unknown')
            if source not in source_analysis:
                source_analysis[source] = {
                    'count': 0,
                    'avg_text_length': 0,
                    'locations': set()
                }
            
            source_analysis[source]['count'] += 1
            source_analysis[source]['avg_text_length'] += len(item.get('text', ''))
            source_analysis[source]['locations'].add(item.get('location', 'Unknown'))
        
        # å¹³å‡è¨ˆç®—
        for source in source_analysis:
            count = source_analysis[source]['count']
            if count > 0:
                source_analysis[source]['avg_text_length'] /= count
            source_analysis[source]['unique_locations'] = len(source_analysis[source]['locations'])
            del source_analysis[source]['locations']  # setã¯JSONåŒ–ã§ããªã„ã®ã§å‰Šé™¤
        
        print(f"âœ… Combined Pipeline Results:")
        print(f"   Total documents: {len(combined_data)}")
        print(f"\nğŸ“Š Source Analysis:")
        
        for source, stats in source_analysis.items():
            print(f"   {source}:")
            print(f"     - Documents: {stats['count']}")
            print(f"     - Avg text length: {stats['avg_text_length']:.1f} chars")
            print(f"     - Unique locations: {stats['unique_locations']}")
        
        # ãƒ‡ãƒ¼ã‚¿ä¿å­˜
        output_file = Path(config.output_dir) / "demo_combined_results.json"
        output_file.parent.mkdir(exist_ok=True)
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump({
                'total_documents': len(combined_data),
                'source_analysis': source_analysis,
                'sample_data': combined_data[:5]  # æœ€åˆã®5ä»¶ã®ã‚µãƒ³ãƒ—ãƒ«
            }, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ Results saved to: {output_file}")
        
        return combined_data
        
    except Exception as e:
        logger.error(f"Combined pipeline failed: {e}")
        return []

def main():
    """ãƒ¡ã‚¤ãƒ³ãƒ‡ãƒ¢å®Ÿè¡Œ"""
    print("ğŸ”¥ NASA FIRMS Integration Demo Suite")
    print("=" * 60)
    print("Demonstrating template-based and real data collection")
    print("=" * 60)
    
    # 1. ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ™ãƒ¼ã‚¹ãƒ‡ãƒ¢
    template_data = demo_template_based_collection()
    
    print("\n" + "="*60)
    
    # 2. å®Ÿãƒ‡ãƒ¼ã‚¿åé›†ãƒ‡ãƒ¢
    real_data = demo_real_data_collection_simulation()
    
    print("\n" + "="*60)
    
    # 3. çµ±åˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãƒ‡ãƒ¢
    combined_data = demo_combined_pipeline()
    
    print("\n" + "="*60)
    print("ğŸ‰ Demo Suite Completed!")
    print(f"ğŸ“ˆ Summary:")
    print(f"   Template data: {len(template_data)} documents")
    print(f"   Real data: {len(real_data)} documents")
    print(f"   Combined pipeline: {len(combined_data)} documents")
    
    if not os.getenv('NASA_FIRMS_MAP_KEY'):
        print(f"\nğŸ’¡ Next steps:")
        print(f"   - Get NASA FIRMS MAP_KEY for real data collection")
        print(f"   - Integrate with v0-7 sentiment analysis pipeline")
        print(f"   - Scale up to production volumes (1K-10K documents)")

if __name__ == "__main__":
    main()